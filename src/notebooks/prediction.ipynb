{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Prediction Model\n",
    "\n",
    "This notebook trains a simple churn prediction model and makes predictions on input data.\n",
    "\n",
    "## Parameters\n",
    "- `input_file`: Path to input CSV file\n",
    "- `output_file`: Path to save predictions JSON\n",
    "- `model_version`: Model version identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Default parameters (will be overridden by papermill)\n",
    "input_file = \"../data/input/sample_customers.csv\"\n",
    "output_file = \"../data/output/predictions.json\"\n",
    "model_version = \"v0.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Model Version: {model_version}\")\n",
    "print(f\"Input File: {input_file}\")\n",
    "print(f\"Output File: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input data\n",
    "df = pd.read_csv(input_file)\n",
    "print(f\"Loaded {len(df)} records\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for prediction\n",
    "# We'll use a simple approach: encode categorical variables and select key features\n",
    "\n",
    "# Make a copy for processing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Select features for the model\n",
    "feature_columns = [\n",
    "    'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n",
    "    'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
    "    'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
    "    'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod',\n",
    "    'MonthlyCharges', 'TotalCharges'\n",
    "]\n",
    "\n",
    "# Handle TotalCharges (convert to numeric)\n",
    "df_processed['TotalCharges'] = pd.to_numeric(df_processed['TotalCharges'], errors='coerce')\n",
    "df_processed['TotalCharges'].fillna(df_processed['MonthlyCharges'], inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = df_processed[feature_columns].select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(f\"Processed {len(categorical_columns)} categorical features\")\n",
    "print(f\"Feature shape: {df_processed[feature_columns].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Simple Model\n",
    "\n",
    "For demonstration purposes, we'll create a simple model with synthetic training data.\n",
    "In production, you would load a pre-trained model or train on actual historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple heuristic-based \"model\" for demonstration\n",
    "# In production, you would load a pre-trained model\n",
    "\n",
    "def predict_churn_probability(row):\n",
    "    \"\"\"\n",
    "    Simple heuristic-based churn prediction.\n",
    "    Higher probability if:\n",
    "    - Month-to-month contract\n",
    "    - Low tenure\n",
    "    - High monthly charges\n",
    "    - Electronic check payment\n",
    "    \"\"\"\n",
    "    score = 0.3  # Base probability\n",
    "    \n",
    "    # Contract type influence (encoded values)\n",
    "    if row['Contract'] == 0:  # Month-to-month typically encoded as 0\n",
    "        score += 0.3\n",
    "    \n",
    "    # Tenure influence\n",
    "    if row['tenure'] < 12:\n",
    "        score += 0.2\n",
    "    elif row['tenure'] > 48:\n",
    "        score -= 0.2\n",
    "    \n",
    "    # Monthly charges influence\n",
    "    if row['MonthlyCharges'] > 80:\n",
    "        score += 0.15\n",
    "    \n",
    "    # Payment method influence\n",
    "    if row['PaymentMethod'] == 2:  # Electronic check\n",
    "        score += 0.1\n",
    "    \n",
    "    # Ensure probability is between 0 and 1\n",
    "    return max(0.0, min(1.0, score))\n",
    "\n",
    "print(\"Model ready for predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "predictions = df_processed[feature_columns].apply(predict_churn_probability, axis=1).tolist()\n",
    "\n",
    "print(f\"Generated {len(predictions)} predictions\")\n",
    "print(f\"Sample predictions: {predictions[:5]}\")\n",
    "print(f\"Average churn probability: {np.mean(predictions):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to JSON file\n",
    "import os\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(predictions, f, indent=2)\n",
    "\n",
    "print(f\"Predictions saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary statistics\n",
    "summary = {\n",
    "    'model_version': model_version,\n",
    "    'total_predictions': len(predictions),\n",
    "    'high_risk_customers': sum(1 for p in predictions if p > 0.7),\n",
    "    'medium_risk_customers': sum(1 for p in predictions if 0.4 <= p <= 0.7),\n",
    "    'low_risk_customers': sum(1 for p in predictions if p < 0.4),\n",
    "    'average_churn_probability': float(np.mean(predictions)),\n",
    "    'max_churn_probability': float(np.max(predictions)),\n",
    "    'min_churn_probability': float(np.min(predictions))\n",
    "}\n",
    "\n",
    "print(\"\\n=== Prediction Summary ===\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nâœ“ Prediction completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
